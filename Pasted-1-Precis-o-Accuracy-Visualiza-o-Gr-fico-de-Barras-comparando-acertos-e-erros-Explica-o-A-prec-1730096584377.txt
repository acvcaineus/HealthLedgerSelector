1. Precisão (Accuracy)
Visualização: Gráfico de Barras comparando acertos e erros
Explicação: A precisão é uma métrica fundamental que avalia a proporção de decisões corretas (acertos) em relação ao total de decisões tomadas pela árvore de decisão. No contexto de escolha de tecnologias de ledger distribuído (DLTs) para saúde, essa métrica indica a taxa de sucesso do framework em recomendar a DLT mais adequada para cada situação.
Interpretação:
Valores altos de precisão: Indicativos de um sistema com alta taxa de acertos, adequado para suportar decisões em ambientes críticos como o setor de saúde.
Valores baixos de precisão: Podem indicar necessidade de ajustes no modelo para melhorar a recomendação de DLTs.
Fórmula:
Precis
a
˜
o
=
N
u
ˊ
mero de Decis
o
˜
es Corretas
Total de Decis
o
˜
es
Precis 
a
˜
 o= 
Total de Decis 
o
˜
 es
N 
u
ˊ
 mero de Decis 
o
˜
 es Corretas
​	
 
Número de Decisões Corretas: Total de DLTs recomendadas que atendem efetivamente aos critérios do setor de saúde.
Total de Decisões: Soma de todas as decisões realizadas pelo framework, incluindo acertos e erros.
2. Sensibilidade (Recall ou Sensitivity)
Visualização: Curva ROC (Receiver Operating Characteristic) para medir a capacidade de detecção correta de casos positivos.
Explicação: A sensibilidade indica a proporção de casos verdadeiramente positivos que o modelo identificou corretamente. No caso do "SeletorDLTSaude", a sensibilidade mede a capacidade do sistema de identificar corretamente tecnologias que realmente atendem aos requisitos críticos de saúde.
Interpretação:
Alta sensibilidade: Indica eficácia em identificar soluções que atendem aos critérios críticos do setor.
Baixa sensibilidade: Sugere uma possível falha em reconhecer tecnologias adequadas, exigindo revisão dos critérios de seleção.
Fórmula:
Sensibilidade
=
Verdadeiros Positivos
Verdadeiros Positivos
+
Falsos Negativos
Sensibilidade= 
Verdadeiros Positivos+Falsos Negativos
Verdadeiros Positivos
​	
 
Verdadeiros Positivos (VP): Casos onde a DLT recomendada realmente atende aos critérios exigidos.
Falsos Negativos (FN): Casos onde uma DLT que atenderia aos critérios não foi recomendada pelo sistema.
3. Especificidade (Specificity)
Visualização: Matriz de Confusão para diferenciar casos corretos de falsos positivos.
Explicação: A especificidade mede a capacidade da árvore de decisão de identificar corretamente as tecnologias que não atendem aos critérios de escolha, ajudando a evitar recomendações inadequadas.
Interpretação:
Alta especificidade: A árvore exclui de forma eficiente DLTs que não são compatíveis com as necessidades de segurança e eficiência.
Baixa especificidade: Sugere que o modelo pode estar recomendando opções inadequadas.
Fórmula:
Especificidade
=
Verdadeiros Negativos
Verdadeiros Negativos
+
Falsos Positivos
Especificidade= 
Verdadeiros Negativos+Falsos Positivos
Verdadeiros Negativos
​	
 
Verdadeiros Negativos (VN): Casos onde o sistema corretamente excluiu uma DLT inadequada.
Falsos Positivos (FP): Casos onde o sistema recomendou uma DLT que não atende aos requisitos estabelecidos.
4. Profundidade da Árvore
Visualização: Diagrama Hierárquico da Árvore Decisória para ilustrar a estrutura de decisão.
Explicação: A profundidade da árvore refere-se ao número de níveis de decisão. Em DLTs, uma árvore mais profunda pode indicar uma avaliação mais complexa e detalhada.
Interpretação:
Maior profundidade: Sinal de complexidade, mas pode capturar nuances importantes.
Menor profundidade: Facilita a interpretação e comunicação dos resultados, mas pode perder detalhes.
Valor da Profundidade:
Profundidade da 
A
ˊ
rvore
=
3.5
Profundidade da  
A
ˊ
 rvore=3.5
A profundidade considera a necessidade de um equilíbrio entre detalhamento e simplicidade.
5. Complexidade da Árvore
Visualização: Gráfico de Barras Empilhadas para comparar o número de nós e ramos.
Explicação: A complexidade mede o número total de nós e ramos, o que afeta a interpretabilidade e eficiência da árvore.
Interpretação:
Alta complexidade: Captura mais detalhes, mas dificulta a leitura.
Baixa complexidade: Facilita a compreensão, mas pode reduzir precisão.
Taxa de Poda:
Taxa de Poda
=
52.94
%
Taxa de Poda=52.94%
O valor indica que ramos foram removidos para reduzir complexidade e melhorar a generalização.
6. Entropia
Visualização: Gráfico de Barras ou Linhas para mostrar variação na entropia entre diferentes decisões.
Explicação: A entropia mede a aleatoriedade no conjunto de decisões da árvore, com menor entropia indicando maior consistência.
Interpretação:
Baixa entropia: Sugere um conjunto de decisões mais consistente e confiável.
Alta entropia: Indica incerteza, refletindo uma menor confiabilidade nas recomendações.
Fórmula:
Entropia
=
−
∑
i
=
1
n
p
i
log
⁡
2
(
p
i
)
Entropia=− 
i=1
∑
n
​	
 p 
i
​	
 log 
2
​	
 (p 
i
​	
 )
Onde 
p
i
p 
i
​	
  representa a probabilidade de cada classe; o logaritmo base 2 fornece uma medida em bits, facilitando a avaliação da incerteza.
Use esta estrutura para facilitar a compreensão e visualização das métricas de desempenho da árvore decisória no processo de seleção de DLTs no setor de saúde.